{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XimenaRamirezA/AI-FIME-2024/blob/main/Analisis%20de%20pat%C3%B3genos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1- Carga de Datos"
      ],
      "metadata": {
        "id": "bxB5GdwC1mWB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nko4gRXCjzzk"
      },
      "outputs": [],
      "source": [
        "# Importación de librerías\n",
        "import os  # Para manejo de archivos y directorios\n",
        "import cv2  # OpenCV para procesamiento de imágenes\n",
        "import numpy as np  # Manipulación de arrays numéricos\n",
        "import matplotlib.pyplot as plt  # Visualización de resultados\n",
        "from sklearn.model_selection import train_test_split  # División de datos\n",
        "from sklearn.preprocessing import LabelEncoder  # Codificación de etiquetas\n",
        "from keras.utils import to_categorical  # Codificación one-hot\n",
        "import tensorflow as tf  # Framework para deep learning\n",
        "from tensorflow.keras import layers, models  # Componentes para construir la red\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2- Carga y Preprocesamiento de Imagenes"
      ],
      "metadata": {
        "id": "si2oLxqf2Ykk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuración de rutas y parámetros\n",
        "DATA_DIR = '/content/microscopy_dataset'  # Ruta del dataset de imágenes\n",
        "IMG_SIZE = (164, 164)  # Tamaño al que se redimensionarán las imágenes\n",
        "\n",
        "# Listas para almacenar imágenes y etiquetas\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Procesamiento de las imágenes\n",
        "for category in sorted(os.listdir(DATA_DIR)):\n",
        "    category_path = os.path.join(DATA_DIR, category)\n",
        "    if os.path.isdir(category_path):\n",
        "        for img_name in os.listdir(category_path):\n",
        "            img_path = os.path.join(category_path, img_name)\n",
        "            img = cv2.imread(img_path)  # Carga la imagen\n",
        "\n",
        "            if img is not None:\n",
        "                # Preprocesamiento:\n",
        "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convertir a escala de grises\n",
        "                resized = cv2.resize(gray, IMG_SIZE)  # Redimensionar\n",
        "                images.append(resized)\n",
        "                labels.append(category)  # Almacena la etiqueta\n",
        "\n",
        "# Preparación de los datos para el modelo\n",
        "images = np.array(images).reshape(-1, 164, 164, 1) / 255.0  # Normalización (0-1)\n",
        "labels = np.array(labels)  # Convertir a array numpy\n"
      ],
      "metadata": {
        "id": "dwleHGM7rRrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3- Preparación de los datos para el modelo"
      ],
      "metadata": {
        "id": "JhdDLyDg2wJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Codificación de etiquetas\n",
        "le = LabelEncoder()\n",
        "labels_encoded = le.fit_transform(labels)  # Convertir etiquetas a números\n",
        "labels_onehot = to_categorical(labels_encoded)  # Codificación one-hot (opcional)\n",
        "\n",
        "# División del dataset (80% entrenamiento, 20% prueba)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    images, labels_encoded, test_size=0.2, random_state=42)\n",
        "num_classes = len(np.unique(labels_encoded))  # Número de clases\n"
      ],
      "metadata": {
        "id": "1i8JYKxUrW1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4- Construcción del modelo CNN y Compilacion del modelo"
      ],
      "metadata": {
        "id": "B9QwO77929h_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Construcción del modelo CNN\n",
        "model = models.Sequential([\n",
        "    # Capa convolucional 1\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(164, 164, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),  # Reducción dimensional\n",
        "\n",
        "    # Capa convolucional 2\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Capa convolucional 3\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "\n",
        "    # Capas densas (fully connected)\n",
        "    layers.Flatten(),  # Aplanar para conexión densa\n",
        "    layers.Dense(64, activation='relu'),  # Capa oculta\n",
        "    layers.Dense(num_classes, activation='softmax')  # Capa de salida\n",
        "])\n",
        "\n",
        "# Compilación del modelo\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',  # Función de pérdida\n",
        "              metrics=['accuracy'])  # Métrica a monitorear\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "history = model.fit(X_train, y_train,\n",
        "                   epochs=10,  # Número de iteraciones\n",
        "                   validation_data=(X_test, y_test))  # Datos de validación\n",
        "\n"
      ],
      "metadata": {
        "id": "SVsP3n69rZDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Visualización y evaluación"
      ],
      "metadata": {
        "id": "rp_GiW6E3Xy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualización del rendimiento\n",
        "plt.plot(history.history['accuracy'], label='Precisión en entrenamiento')\n",
        "plt.plot(history.history['val_accuracy'], label='Precisión en validación')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Precisión')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Cl4qbk_7raIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prueba con una imagen del conjunto de test\n",
        "index = 0  # Índice de la imagen a probar\n",
        "sample = np.expand_dims(X_test[index], axis=0)  # Preparar muestra para predicción\n",
        "prediction = np.argmax(model.predict(sample))  # Obtener predicción\n",
        "true_label = y_test[index]  # Etiqueta real\n",
        "\n",
        "# Mostrar resultados\n",
        "print(f\"Predicción del modelo: {le.inverse_transform([prediction])[0]}\")\n",
        "print(f\"Etiqueta real: {le.inverse_transform([true_label])[0]}\")\n",
        "\n",
        "# Visualizar la imagen\n",
        "plt.imshow(X_test[index].reshape(164, 164), cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Ntkxj_ncrc3V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}